# =============================================================================
# RAPTOR v2.1.1 Pipeline Configurations
# =============================================================================
# Detailed configurations for all 8 RNA-seq analysis pipelines
#
# Each pipeline includes:
#   - Complete tool parameters
#   - Performance characteristics
#   - Recommended use cases
#   - Resource requirements
#   - Decision criteria
#
# NEW in v2.1.1: Pipelines now integrate with Adaptive Threshold Optimizer
# for data-driven significance threshold selection. Use threshold_optimizer
# settings in your config to optimize thresholds based on your data.
#
# Author: Ayeh Bolouki
# Affiliation: University of Namur, Belgium
# Email: ayehbolouki1988@gmail.com
# License: MIT
# =============================================================================

# -----------------------------------------------------------------------------
# Pipeline 1: STAR-RSEM-DESeq2
# -----------------------------------------------------------------------------
pipeline_1:
  name: "STAR-RSEM-DESeq2"
  type: "alignment-based"
  description: "Gold standard pipeline with splice-aware alignment, isoform-level quantification, and robust statistical testing"
  
  components:
    alignment: "STAR"
    quantification: "RSEM"
    statistics: "DESeq2"
  
  characteristics:
    accuracy: 0.95        # Excellent accuracy
    speed: 0.60           # Moderate speed
    memory: 0.50          # High memory usage (~32GB)
    sensitivity: 0.94     # Very high sensitivity
    specificity: 0.96     # Very high specificity
    transcript_level: true
    gene_level: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "deseq2"  # Column names: log2FoldChange, pvalue, padj
    default_columns:
      logfc: "log2FoldChange"
      pvalue: "pvalue"
      padj: "padj"
      basemean: "baseMean"
  
  parameters:
    star:
      genomeDir: null  # Must be provided
      runThreadN: 8
      readFilesCommand: "zcat"
      outFilterType: "BySJout"
      outFilterMultimapNmax: 20
      alignSJoverhangMin: 8
      alignSJDBoverhangMin: 1
      outFilterMismatchNmax: 999
      outFilterMismatchNoverReadLmax: 0.04
      alignIntronMin: 20
      alignIntronMax: 1000000
      alignMatesGapMax: 1000000
      outSAMtype: "BAM SortedByCoordinate"
      outSAMunmapped: "Within"
      outSAMattributes: "NH HI AS NM MD"
      quantMode: "TranscriptomeSAM"
    
    rsem:
      reference: null  # Must be provided
      num_threads: 8
      forward_prob: 0.5  # 0 for reverse-stranded, 1 for forward-stranded
      estimate_rspd: true
      calc_ci: true
      ci_memory: 30000
      seed: 42
      output_genome_bam: false
    
    deseq2:
      design_formula: "~ condition"
      fdr_threshold: 0.05  # Can be optimized by ATO
      lfc_threshold: 0     # Can be optimized by ATO
      cook_cutoff: true
      independent_filtering: true
      alpha: 0.05
      test: "Wald"  # Wald or LRT
      fit_type: "parametric"  # parametric, local, or mean
      sf_type: "ratio"  # ratio or poscounts
      beta_prior: false
      parallel: false
  
  resource_requirements:
    min_threads: 4
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 32
    recommended_memory_gb: 48
    disk_space_gb: 100
  
  performance_benchmarks:
    small_dataset:  # <10 samples, <10M reads
      runtime_hours: 2.0
      peak_memory_gb: 35
    medium_dataset:  # 10-20 samples, 10-30M reads
      runtime_hours: 6.0
      peak_memory_gb: 40
    large_dataset:  # >20 samples, >30M reads
      runtime_hours: 12.0
      peak_memory_gb: 48
  
  recommended_for:
    - "Publication-quality analysis"
    - "Well-powered studies (n≥6 per group)"
    - "When transcript-level analysis is needed"
    - "Complex experimental designs"
    - "Reference genome available"
    - "When highest accuracy is priority"
  
  not_recommended_for:
    - "Limited computational resources"
    - "Very large datasets (>50 samples)"
    - "Quick exploratory analysis"
    - "Non-model organisms without good reference"
  
  output_files:
    - "gene_counts.csv"
    - "transcript_counts.csv"
    - "deseq2_results.csv"
    - "normalized_counts.csv"
    - "alignment_stats.txt"

# -----------------------------------------------------------------------------
# Pipeline 2: HISAT2-StringTie-Ballgown
# -----------------------------------------------------------------------------
pipeline_2:
  name: "HISAT2-StringTie-Ballgown"
  type: "alignment-based"
  description: "Fast alignment with transcript assembly and isoform-level differential expression"
  
  components:
    alignment: "HISAT2"
    assembly: "StringTie"
    quantification: "StringTie"
    statistics: "Ballgown"
  
  characteristics:
    accuracy: 0.88
    speed: 0.75
    memory: 0.70
    sensitivity: 0.87
    specificity: 0.89
    transcript_level: true
    gene_level: true
    novel_transcript_detection: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "ballgown"
    default_columns:
      logfc: "fc"  # Fold change needs log2 transformation
      pvalue: "pval"
      padj: "qval"
  
  parameters:
    hisat2:
      index: null  # Must be provided
      threads: 8
      dta: true  # Downstream transcriptome assembly
      dta_cufflinks: false
      rna_strandness: "unstranded"  # unstranded, F, or R
      min_intronlen: 20
      max_intronlen: 500000
      known_splicesite_infile: null
      novel_splicesite_outfile: "splicesites.txt"
      summary_file: "alignment_summary.txt"
    
    stringtie:
      threads: 8
      reference_gtf: null  # Recommended for better results
      output_gtf: "stringtie.gtf"
      abundance_file: "abundances.txt"
      min_isoform_abundance: 0.1
      min_junction_coverage: 1
      min_junction_reads: 1
      min_transcript_len: 200
      coverage_file: "coverage.gtf"
      ballgown_output: true
    
    ballgown:
      design: "~ condition"
      covariate_adjust: []
      fdr_threshold: 0.05  # Can be optimized by ATO
      fc_threshold: 1.0    # Can be optimized by ATO
      feature_type: "transcript"  # transcript or gene
      time_series: false
  
  resource_requirements:
    min_threads: 4
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 16
    recommended_memory_gb: 24
    disk_space_gb: 80
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 1.5
      peak_memory_gb: 18
    medium_dataset:
      runtime_hours: 4.0
      peak_memory_gb: 22
    large_dataset:
      runtime_hours: 8.0
      peak_memory_gb: 28
  
  recommended_for:
    - "Novel transcript discovery"
    - "Isoform-level analysis"
    - "When reference annotation incomplete"
    - "Time-series experiments"
    - "Faster alternative to Pipeline 1"
  
  not_recommended_for:
    - "When highest accuracy needed"
    - "Very short reads (<50bp)"
    - "When no reference genome available"
  
  output_files:
    - "gene_counts.csv"
    - "transcript_counts.csv"
    - "assembled_transcripts.gtf"
    - "ballgown_results.csv"
    - "novel_transcripts.gtf"

# -----------------------------------------------------------------------------
# Pipeline 3: Salmon-edgeR
# -----------------------------------------------------------------------------
pipeline_3:
  name: "Salmon-edgeR"
  type: "alignment-free"
  description: "Ultra-fast pseudo-alignment with robust statistical testing - ideal for large-scale studies"
  
  components:
    quantification: "Salmon"
    statistics: "edgeR"
  
  characteristics:
    accuracy: 0.90
    speed: 0.95
    memory: 0.90
    sensitivity: 0.89
    specificity: 0.91
    transcript_level: true
    gene_level: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "edger"
    default_columns:
      logfc: "logFC"
      pvalue: "PValue"
      padj: "FDR"
      logcpm: "logCPM"
  
  parameters:
    salmon:
      index: null  # Must be provided
      lib_type: "A"  # Automatic detection
      num_threads: 8
      num_bootstraps: 30
      validate_mappings: true
      gc_bias: false
      seq_bias: false
      pos_bias: false
      use_vbopt: false
      num_gibbs_samples: 0
      min_assigned_frags: 10
      range_factorization_bins: 4
      output: "quant"
    
    edger:
      design_formula: "~ condition"
      normalization_method: "TMM"  # TMM, RLE, upperquartile, none
      fdr_threshold: 0.05  # Can be optimized by ATO
      lfc_threshold: 0     # Can be optimized by ATO
      prior_count: 2
      robust: false
      trend_method: "locfit"  # locfit, loess, none
      dispersion_method: "common"  # common, trended, tagwise
      test_method: "glmQLFTest"  # glmQLFTest, glmLRT, exactTest
      min_count: 10
      min_total_count: 15
      min_prop: 0.7
  
  resource_requirements:
    min_threads: 2
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 8
    recommended_memory_gb: 16
    disk_space_gb: 30
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 0.5
      peak_memory_gb: 10
    medium_dataset:
      runtime_hours: 1.5
      peak_memory_gb: 14
    large_dataset:
      runtime_hours: 3.0
      peak_memory_gb: 18
  
  recommended_for:
    - "Large-scale studies (>20 samples)"
    - "Exploratory analysis"
    - "Limited computational resources"
    - "Quick turnaround time needed"
    - "Batch processing multiple datasets"
  
  not_recommended_for:
    - "When alignment BAM files needed"
    - "Novel transcript discovery"
    - "Very short reads (<50bp)"
  
  output_files:
    - "gene_counts.csv"
    - "transcript_counts.csv"
    - "edger_results.csv"
    - "normalized_counts.csv"

# -----------------------------------------------------------------------------
# Pipeline 4: Kallisto-DESeq2
# -----------------------------------------------------------------------------
pipeline_4:
  name: "Kallisto-DESeq2"
  type: "alignment-free"
  description: "Fast k-mer based quantification with robust statistical testing"
  
  components:
    quantification: "Kallisto"
    statistics: "DESeq2"
  
  characteristics:
    accuracy: 0.89
    speed: 0.92
    memory: 0.88
    sensitivity: 0.88
    specificity: 0.90
    transcript_level: true
    gene_level: true
    bootstrap_support: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "deseq2"
    default_columns:
      logfc: "log2FoldChange"
      pvalue: "pvalue"
      padj: "padj"
      basemean: "baseMean"
  
  parameters:
    kallisto:
      index: null  # Must be provided
      threads: 8
      bootstrap_samples: 100
      seed: 42
      single: false  # True for single-end reads
      fragment_length: null  # Required for single-end
      sd: null  # Required for single-end
      bias: false
      fusion: false
      pseudobam: false
    
    deseq2:
      design_formula: "~ condition"
      fdr_threshold: 0.05  # Can be optimized by ATO
      lfc_threshold: 0     # Can be optimized by ATO
      cook_cutoff: true
      independent_filtering: true
      alpha: 0.05
      test: "Wald"
      fit_type: "parametric"
      sf_type: "ratio"
      beta_prior: false
  
  resource_requirements:
    min_threads: 2
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 8
    recommended_memory_gb: 16
    disk_space_gb: 30
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 0.3
      peak_memory_gb: 8
    medium_dataset:
      runtime_hours: 1.0
      peak_memory_gb: 12
    large_dataset:
      runtime_hours: 2.5
      peak_memory_gb: 16
  
  recommended_for:
    - "Fastest analysis needed"
    - "Limited resources"
    - "Uncertainty quantification (bootstraps)"
    - "Large sample numbers"
    - "Repeated analyses"
  
  not_recommended_for:
    - "Novel transcript discovery"
    - "When alignment needed"
    - "Reads with many sequencing errors"
  
  output_files:
    - "gene_counts.csv"
    - "transcript_counts.csv"
    - "deseq2_results.csv"
    - "bootstrap_abundances.h5"

# -----------------------------------------------------------------------------
# Pipeline 5: STAR-featureCounts-limma-voom
# -----------------------------------------------------------------------------
pipeline_5:
  name: "STAR-featureCounts-limma-voom"
  type: "alignment-based"
  description: "High-accuracy alignment with gene-level counting and linear modeling"
  
  components:
    alignment: "STAR"
    quantification: "featureCounts"
    statistics: "limma-voom"
  
  characteristics:
    accuracy: 0.93
    speed: 0.65
    memory: 0.55
    sensitivity: 0.92
    specificity: 0.94
    transcript_level: false
    gene_level: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "limma"
    default_columns:
      logfc: "logFC"
      pvalue: "P.Value"
      padj: "adj.P.Val"
      aveexpr: "AveExpr"
  
  parameters:
    star:
      genomeDir: null
      runThreadN: 8
      readFilesCommand: "zcat"
      outFilterType: "BySJout"
      outFilterMultimapNmax: 20
      alignSJoverhangMin: 8
      alignSJDBoverhangMin: 1
      outFilterMismatchNmax: 999
      outFilterMismatchNoverReadLmax: 0.04
      alignIntronMin: 20
      alignIntronMax: 1000000
      alignMatesGapMax: 1000000
      outSAMtype: "BAM SortedByCoordinate"
      outSAMunmapped: "Within"
      outSAMattributes: "NH HI AS NM MD"
    
    featurecounts:
      gtf: null  # Must be provided
      threads: 8
      feature_type: "exon"
      attribute_type: "gene_id"
      min_overlap: 1
      min_mapping_quality: 10
      count_multi_mapping: false
      count_multi_overlap: false
      fraction: false
      primary_only: false
      ignore_dup: false
      strandedness: 0  # 0=unstranded, 1=stranded, 2=reversely stranded
    
    limma_voom:
      design_formula: "~ condition"
      normalization_method: "TMM"
      fdr_threshold: 0.05  # Can be optimized by ATO
      lfc_threshold: 0     # Can be optimized by ATO
      robust: true
      treat: false  # Use treat() for hypothesis testing with fold change
      adjust_method: "BH"
      duplicate_correlation: null
      block: null
  
  resource_requirements:
    min_threads: 4
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 32
    recommended_memory_gb: 40
    disk_space_gb: 80
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 2.5
      peak_memory_gb: 36
    medium_dataset:
      runtime_hours: 6.5
      peak_memory_gb: 42
    large_dataset:
      runtime_hours: 13.0
      peak_memory_gb: 50
  
  recommended_for:
    - "Complex experimental designs"
    - "Gene-level analysis sufficient"
    - "Batch effect correction needed"
    - "Duplicate sample handling"
    - "Flexible linear modeling"
  
  not_recommended_for:
    - "Transcript-level analysis"
    - "Limited computational resources"
    - "Novel transcript discovery"
  
  output_files:
    - "gene_counts.csv"
    - "limma_results.csv"
    - "normalized_counts.csv"
    - "voom_weights.csv"

# -----------------------------------------------------------------------------
# Pipeline 6: Salmon-NOISeq
# -----------------------------------------------------------------------------
pipeline_6:
  name: "Salmon-NOISeq"
  type: "alignment-free"
  description: "Non-parametric method for small sample sizes without replicates"
  
  components:
    quantification: "Salmon"
    statistics: "NOISeq"
  
  characteristics:
    accuracy: 0.80
    speed: 0.90
    memory: 0.85
    sensitivity: 0.78
    specificity: 0.82
    transcript_level: true
    gene_level: true
    no_replicates: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "noiseq"
    notes: "NOISeq uses probability instead of p-value"
    default_columns:
      logfc: "M"  # log2 ratio
      prob: "prob"  # Probability (not p-value)
  
  parameters:
    salmon:
      index: null
      lib_type: "A"
      num_threads: 8
      num_bootstraps: 30
      validate_mappings: true
      gc_bias: false
    
    noiseq:
      conditions: null  # Must be provided
      factor: "condition"
      k: 0.5
      norm: "tmm"  # tmm, rpkm, uqua, n
      filter: 1  # CPM filter
      cv_cutoff: 100
      cpm: 1
      pnr: 0.2
      nss: 5
      v: 0.02
      lc: 0  # Length correction
      replicates: "technical"  # technical, biological, no
      q_threshold: 0.8  # Probability threshold
  
  resource_requirements:
    min_threads: 2
    recommended_threads: 4
    max_threads: 8
    min_memory_gb: 8
    recommended_memory_gb: 12
    disk_space_gb: 20
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 0.5
      peak_memory_gb: 8
    medium_dataset:
      runtime_hours: 1.0
      peak_memory_gb: 10
    large_dataset:
      runtime_hours: 2.0
      peak_memory_gb: 14
  
  recommended_for:
    - "No biological replicates"
    - "Very small sample sizes"
    - "Technical replicates only"
    - "Exploratory/pilot studies"
    - "Non-parametric approach preferred"
  
  not_recommended_for:
    - "Publication-quality analysis"
    - "Well-powered studies"
    - "When p-values required"
  
  output_files:
    - "gene_counts.csv"
    - "noiseq_results.csv"
    - "expression_plots.pdf"

# -----------------------------------------------------------------------------
# Pipeline 7: Bowtie2-RSEM-EBSeq
# -----------------------------------------------------------------------------
pipeline_7:
  name: "Bowtie2-RSEM-EBSeq"
  type: "alignment-based"
  description: "Memory-efficient alignment with isoform quantification and empirical Bayes statistics"
  
  components:
    alignment: "Bowtie2"
    quantification: "RSEM"
    statistics: "EBSeq"
  
  characteristics:
    accuracy: 0.87
    speed: 0.68
    memory: 0.75
    sensitivity: 0.86
    specificity: 0.88
    transcript_level: true
    gene_level: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "ebseq"
    notes: "EBSeq uses PPDE (posterior probability of DE)"
    default_columns:
      logfc: "PostFC"  # Posterior fold change
      ppde: "PPDE"     # Posterior probability of DE
  
  parameters:
    bowtie2:
      index: null  # Must be provided
      threads: 8
      mode: "sensitive"  # fast, sensitive, very-sensitive
      min_score: "L,0,-0.6"
      mp: "6,2"  # Max and min mismatch penalties
      rdg: "5,3"  # Read gap penalties
      rfg: "5,3"  # Reference gap penalties
      score_min: "L,-0.6,-0.6"
      no_mixed: false
      no_discordant: false
      time: true
    
    rsem:
      reference: null
      num_threads: 8
      forward_prob: 0.5
      estimate_rspd: true
      calc_ci: false
      ci_memory: 20000
      seed: 42
      output_genome_bam: false
      sampling_for_bam: false
    
    ebseq:
      design_type: "TwoConditions"  # TwoConditions, MultiConditions
      fdr_threshold: 0.05  # Can be optimized by ATO
      fc_threshold: 1.0    # Can be optimized by ATO
      num_iterations: 5
      num_bins: 20
      max_rounds: 20
      pool_variance: false
      quantile_cutoff: 0.75
      isoform_level: false
  
  resource_requirements:
    min_threads: 4
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 16
    recommended_memory_gb: 24
    disk_space_gb: 70
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 3.0
      peak_memory_gb: 20
    medium_dataset:
      runtime_hours: 8.0
      peak_memory_gb: 26
    large_dataset:
      runtime_hours: 16.0
      peak_memory_gb: 32
  
  recommended_for:
    - "Moderate resource environments"
    - "Isoform-level analysis"
    - "Small to medium sample sizes"
    - "Two-condition comparisons"
  
  not_recommended_for:
    - "Complex multi-factor designs"
    - "Very large datasets"
    - "When STAR alignment preferred"
  
  output_files:
    - "gene_counts.csv"
    - "transcript_counts.csv"
    - "ebseq_results.csv"
    - "posterior_probabilities.csv"

# -----------------------------------------------------------------------------
# Pipeline 8: HISAT2-Cufflinks-Cuffdiff
# -----------------------------------------------------------------------------
pipeline_8:
  name: "HISAT2-Cufflinks-Cuffdiff"
  type: "alignment-based"
  description: "Classic pipeline with transcript assembly and isoform-level differential expression"
  
  components:
    alignment: "HISAT2"
    assembly: "Cufflinks"
    statistics: "Cuffdiff"
  
  characteristics:
    accuracy: 0.82
    speed: 0.55
    memory: 0.70
    sensitivity: 0.80
    specificity: 0.84
    transcript_level: true
    gene_level: true
    novel_transcript_detection: true
  
  # Threshold Optimizer compatibility (v2.1.1)
  threshold_optimizer_support:
    compatible: true
    output_format: "cuffdiff"
    default_columns:
      logfc: "log2(fold_change)"
      pvalue: "p_value"
      padj: "q_value"
  
  parameters:
    hisat2:
      index: null
      threads: 8
      dta: false
      dta_cufflinks: true
      rna_strandness: "unstranded"
      min_intronlen: 20
      max_intronlen: 500000
    
    cufflinks:
      threads: 8
      reference_gtf: null
      mask_file: null
      frag_bias_correct: null  # Genome fasta for bias correction
      multi_read_correct: false
      library_type: "fr-unstranded"
      upper_quartile_norm: false
      max_bundle_frags: 500000
      min_isoform_fraction: 0.1
      min_intron_length: 50
      max_intron_length: 300000
      overhang_tolerance: 8
      max_multiread_fraction: 0.75
    
    cuffdiff:
      threads: 8
      fdr_threshold: 0.05  # Can be optimized by ATO
      library_type: "fr-unstranded"
      library_norm_method: "geometric"  # classic-fpkm, geometric, quartile
      dispersion_method: "pooled"  # pooled, per-condition, blind
      min_alignment_count: 10
      frag_bias_correct: null
      multi_read_correct: false
      no_effective_length_correction: false
      no_length_correction: false
      compatible_hits_norm: false
      total_hits_norm: false
  
  resource_requirements:
    min_threads: 4
    recommended_threads: 8
    max_threads: 16
    min_memory_gb: 20
    recommended_memory_gb: 32
    disk_space_gb: 100
  
  performance_benchmarks:
    small_dataset:
      runtime_hours: 4.0
      peak_memory_gb: 26
    medium_dataset:
      runtime_hours: 12.0
      peak_memory_gb: 34
    large_dataset:
      runtime_hours: 24.0
      peak_memory_gb: 42
  
  recommended_for:
    - "Legacy analysis reproduction"
    - "Novel transcript discovery"
    - "When Cufflinks ecosystem preferred"
    - "Isoform switching analysis"
  
  not_recommended_for:
    - "New projects (newer methods preferred)"
    - "When speed is priority"
    - "Large-scale studies"
    - "Limited computational resources"
  
  output_files:
    - "gene_exp.diff"
    - "isoform_exp.diff"
    - "assembled_transcripts.gtf"
    - "cuffdiff_results.csv"

# -----------------------------------------------------------------------------
# Pipeline Selection Decision Tree
# -----------------------------------------------------------------------------
decision_tree:
  # Quick selection guide based on data characteristics
  selection_guide:
    
    # Based on sample size
    by_sample_size:
      very_small:  # n < 6
        recommended: [6]  # NOISeq for small samples
        acceptable: [3, 4, 5]
      
      small:  # 6 ≤ n < 12
        recommended: [1, 3, 5]
        acceptable: [2, 4, 6, 7]
      
      medium:  # 12 ≤ n < 24
        recommended: [1, 3, 5]
        acceptable: [2, 4, 7]
      
      large:  # n ≥ 24
        recommended: [3, 4]
        acceptable: [1, 5]
    
    # Based on computational resources
    by_resources:
      limited:  # <16GB RAM, <4 cores
        recommended: [3, 4]
        not_recommended: [1, 5, 8]
      
      moderate:  # 16-32GB RAM, 4-8 cores
        recommended: [1, 2, 3, 4, 5]
        acceptable: [6, 7]
      
      high:  # >32GB RAM, >8 cores
        recommended: [1, 2, 5]
        acceptable: [3, 4, 6, 7, 8]
    
    # Based on analysis goal
    by_goal:
      publication:
        recommended: [1, 5]
        acceptable: [2, 3]
      
      exploratory:
        recommended: [3, 4]
        acceptable: [2]
      
      transcript_level:
        recommended: [1, 2, 3, 4]
        not_recommended: [5, 6]
      
      gene_level_only:
        recommended: [5, 6]
        acceptable: [1, 3]
      
      novel_transcripts:
        recommended: [2, 8]
        not_recommended: [3, 4, 5, 6]
    
    # Based on data complexity
    by_complexity:
      low_variability:  # BCV < 0.4
        recommended: [3, 4, 5]
        acceptable: [1, 2]
      
      medium_variability:  # 0.4 ≤ BCV < 0.6
        recommended: [1, 5]
        acceptable: [2, 3, 7]
      
      high_variability:  # BCV ≥ 0.6
        recommended: [1, 5, 6]
        not_recommended: [4, 8]

# -----------------------------------------------------------------------------
# Pipeline Comparison Matrix
# -----------------------------------------------------------------------------
comparison_matrix:
  # Relative rankings (1 = best, 8 = worst)
  rankings:
    accuracy: [1, 5, 3, 4, 2, 6, 7, 8]
    speed: [4, 3, 1, 2, 5, 6, 7, 8]
    memory_efficiency: [4, 3, 1, 2, 6, 5, 7, 8]
    ease_of_use: [3, 4, 1, 2, 5, 6, 7, 8]
  
  # Feature support matrix
  features:
    transcript_level: [1, 2, 3, 4, 7, 8]
    gene_level: [1, 2, 3, 4, 5, 6, 7, 8]
    novel_transcripts: [2, 8]
    small_samples: [6, 5, 1]
    large_samples: [3, 4, 1]
    complex_designs: [1, 5, 2]
    bootstrap_uncertainty: [4, 3]
    ato_compatible: [1, 2, 3, 4, 5, 6, 7, 8]  # NEW: All pipelines support ATO

# -----------------------------------------------------------------------------
# Threshold Optimizer Integration (NEW in v2.1.1)
# -----------------------------------------------------------------------------
threshold_optimizer_integration:
  description: |
    All pipelines now integrate with the Adaptive Threshold Optimizer (ATO).
    Instead of using fixed thresholds (|logFC| > 1, padj < 0.05), ATO
    determines data-driven thresholds based on your specific dataset.
  
  supported_output_formats:
    - deseq2:    # Pipelines 1, 4
        columns: ["log2FoldChange", "pvalue", "padj", "baseMean"]
    - edger:     # Pipeline 3
        columns: ["logFC", "PValue", "FDR", "logCPM"]
    - limma:     # Pipeline 5
        columns: ["logFC", "P.Value", "adj.P.Val", "AveExpr"]
    - ballgown:  # Pipeline 2
        columns: ["fc", "pval", "qval"]
    - noiseq:    # Pipeline 6
        columns: ["M", "prob"]
    - ebseq:     # Pipeline 7
        columns: ["PostFC", "PPDE"]
    - cuffdiff:  # Pipeline 8
        columns: ["log2(fold_change)", "p_value", "q_value"]
  
  usage_note: |
    To use ATO with any pipeline, add this to your config:
    
    threshold_optimizer:
      enabled: true
      goal: "discovery"  # or "balanced" or "validation"
    
    ATO will automatically detect column names and optimize thresholds.

# =============================================================================
# End of Pipeline Configurations
# =============================================================================
